{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac0ec122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Modules for ML\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58026060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('liked.xlsx')\n",
    "df = df.drop(columns=['genre','artist_name','track_name','track_id','popularity','time_signature'],axis=1)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "df['key'] = encoder.fit_transform(df['key'])\n",
    "df['mode']=encoder.fit_transform(df['mode'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5185d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "scalled = std.fit_transform(df.drop(['liked'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc7f46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 \n",
    "for column in df.columns[:-1]:\n",
    "    df[column] = scalled[:,i]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c0dbd15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.543055</td>\n",
       "      <td>-1.102643</td>\n",
       "      <td>-0.506525</td>\n",
       "      <td>-1.521379</td>\n",
       "      <td>-0.430144</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-0.316854</td>\n",
       "      <td>-0.612925</td>\n",
       "      <td>-0.881917</td>\n",
       "      <td>-0.932552</td>\n",
       "      <td>-1.186636</td>\n",
       "      <td>0.107766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.320377</td>\n",
       "      <td>0.644374</td>\n",
       "      <td>0.319347</td>\n",
       "      <td>0.384299</td>\n",
       "      <td>-0.430144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.419021</td>\n",
       "      <td>0.530101</td>\n",
       "      <td>-0.881917</td>\n",
       "      <td>1.244975</td>\n",
       "      <td>-0.971649</td>\n",
       "      <td>1.063701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.316939</td>\n",
       "      <td>0.980008</td>\n",
       "      <td>-0.521571</td>\n",
       "      <td>-0.449435</td>\n",
       "      <td>-0.430144</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.607299</td>\n",
       "      <td>0.270532</td>\n",
       "      <td>-0.881917</td>\n",
       "      <td>-0.567955</td>\n",
       "      <td>-0.609094</td>\n",
       "      <td>-1.701363</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.938541</td>\n",
       "      <td>0.704616</td>\n",
       "      <td>-0.265972</td>\n",
       "      <td>-0.231076</td>\n",
       "      <td>-0.430144</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.346044</td>\n",
       "      <td>0.565829</td>\n",
       "      <td>1.133893</td>\n",
       "      <td>-0.814373</td>\n",
       "      <td>0.528507</td>\n",
       "      <td>-0.200456</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.842619</td>\n",
       "      <td>0.050560</td>\n",
       "      <td>-0.154075</td>\n",
       "      <td>0.969898</td>\n",
       "      <td>-0.429951</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.741576</td>\n",
       "      <td>1.129087</td>\n",
       "      <td>-0.881917</td>\n",
       "      <td>-0.434688</td>\n",
       "      <td>-0.023122</td>\n",
       "      <td>-0.102182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms    energy  instrumentalness  key  \\\n",
       "0      1.543055     -1.102643    -0.506525 -1.521379         -0.430144 -1.2   \n",
       "1     -0.320377      0.644374     0.319347  0.384299         -0.430144  0.0   \n",
       "2     -0.316939      0.980008    -0.521571 -0.449435         -0.430144  0.0   \n",
       "3     -0.938541      0.704616    -0.265972 -0.231076         -0.430144 -0.8   \n",
       "4     -0.842619      0.050560    -0.154075  0.969898         -0.429951 -0.8   \n",
       "\n",
       "   liveness  loudness      mode  speechiness     tempo   valence  liked  \n",
       "0 -0.316854 -0.612925 -0.881917    -0.932552 -1.186636  0.107766      1  \n",
       "1 -0.419021  0.530101 -0.881917     1.244975 -0.971649  1.063701      0  \n",
       "2 -0.607299  0.270532 -0.881917    -0.567955 -0.609094 -1.701363      1  \n",
       "3 -0.346044  0.565829  1.133893    -0.814373  0.528507 -0.200456      1  \n",
       "4 -0.741576  1.129087 -0.881917    -0.434688 -0.023122 -0.102182      1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0001c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('liked',axis=1)\n",
    "y = df['liked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ee5736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b073526c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(12, input_shape=(12,), activation='relu'),\n",
    "    keras.layers.Dense(12, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcbee3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 0.8244 - accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8172 - accuracy: 0.5000\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8102 - accuracy: 0.5000\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8033 - accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7965 - accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7897 - accuracy: 0.5833\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7829 - accuracy: 0.5833\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7762 - accuracy: 0.5833\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7696 - accuracy: 0.5833\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7630 - accuracy: 0.5833\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7567 - accuracy: 0.5833\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7503 - accuracy: 0.5833\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7441 - accuracy: 0.5833\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7382 - accuracy: 0.5833\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7324 - accuracy: 0.5833\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7266 - accuracy: 0.5833\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7209 - accuracy: 0.5833\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7152 - accuracy: 0.5833\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7094 - accuracy: 0.5833\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7036 - accuracy: 0.5833\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6979 - accuracy: 0.5833\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5833\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.5833\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.5833\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.5833\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.5833\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6654 - accuracy: 0.5833\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.6667\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.6667\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6502 - accuracy: 0.6667\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6451 - accuracy: 0.6667\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6400 - accuracy: 0.6667\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.7500\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6298 - accuracy: 0.7500\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.7500\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.7500\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.7500\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6101 - accuracy: 0.7500\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6052 - accuracy: 0.7500\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.7500\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5955 - accuracy: 0.7500\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5908 - accuracy: 0.7500\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5861 - accuracy: 0.7500\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5814 - accuracy: 0.7500\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5768 - accuracy: 0.7500\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5722 - accuracy: 0.7500\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.7500\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5631 - accuracy: 0.7500\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.7500\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5541 - accuracy: 0.7500\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5497 - accuracy: 0.7500\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7500\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7500\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5362 - accuracy: 0.7500\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5318 - accuracy: 0.7500\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5273 - accuracy: 0.7500\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.7500\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7500\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7500\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5095 - accuracy: 0.7500\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.7500\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.7500\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7500\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4912 - accuracy: 0.7500\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4774 - accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4495 - accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4448 - accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.9167\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4355 - accuracy: 0.9167\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.9167\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.9167\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.9167\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.9167\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4121 - accuracy: 0.9167\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4075 - accuracy: 0.9167\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4030 - accuracy: 0.9167\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3984 - accuracy: 0.9167\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3940 - accuracy: 0.9167\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3896 - accuracy: 0.9167\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.9167\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3813 - accuracy: 0.9167\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3773 - accuracy: 0.9167\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3732 - accuracy: 0.9167\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3692 - accuracy: 0.9167\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3653 - accuracy: 0.9167\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3613 - accuracy: 0.9167\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3574 - accuracy: 0.9167\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3536 - accuracy: 0.9167\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3497 - accuracy: 0.9167\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3458 - accuracy: 0.9167\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3419 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3382 - accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3308 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3270 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3196 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3127 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3094 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3061 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2994 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2961 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2894 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2828 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2796 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2765 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2734 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2703 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2673 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2642 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2612 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2582 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2553 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2524 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2495 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2467 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2439 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2411 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2384 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2358 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2331 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2305 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2279 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2253 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2227 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2201 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2176 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2151 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2126 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2102 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2078 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2054 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2031 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2007 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1983 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1937 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1914 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1891 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1847 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1825 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1804 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1782 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1761 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1740 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1720 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1700 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1680 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1660 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1640 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1621 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1602 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1583 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1564 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1545 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1527 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1509 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1491 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1439 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1422 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1405 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1389 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1372 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1340 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1324 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1308 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1293 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1278 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1262 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1247 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1233 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1218 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1204 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1175 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1161 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1148 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1134 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1095 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1070 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1057 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1045 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f753a12110>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd791404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step - loss: 0.5117 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5117466449737549, 0.5]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56a4b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data):\n",
    "    pred = model.predict(data).flatten()\n",
    "    pred[pred >= 0.5] = 1\n",
    "    pred[pred < 0.5] = 0\n",
    "    return pred\n",
    "\n",
    "def plot_cm(y_true,y_pred,title=None):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    sns.heatmap(cm, annot=True, fmt='g',cmap='YlGnBu')\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb05ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_test = predict(x_test)\n",
    "plot_cm(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "af0b312b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/Spotify_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model/Spotify_model\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model/Spotify_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c1189440",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_excel('Spotify.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2aa77f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.611</td>\n",
       "      <td>0.389</td>\n",
       "      <td>99373</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3460</td>\n",
       "      <td>-1.828</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>166.969</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.246</td>\n",
       "      <td>0.590</td>\n",
       "      <td>137373</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-5.559</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0868</td>\n",
       "      <td>174.003</td>\n",
       "      <td>0.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.952</td>\n",
       "      <td>0.663</td>\n",
       "      <td>170267</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>-13.879</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>99.488</td>\n",
       "      <td>0.368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.703</td>\n",
       "      <td>0.240</td>\n",
       "      <td>152427</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>-12.178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>171.758</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.331</td>\n",
       "      <td>82625</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.123</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2020</td>\n",
       "      <td>-21.150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>140.576</td>\n",
       "      <td>0.390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   acousticness  danceability  duration_ms  energy  instrumentalness  key  \\\n",
       "0         0.611         0.389        99373   0.910             0.000    4   \n",
       "1         0.246         0.590       137373   0.737             0.000    9   \n",
       "2         0.952         0.663       170267   0.131             0.000    3   \n",
       "3         0.703         0.240       152427   0.326             0.000    4   \n",
       "4         0.950         0.331        82625   0.225             0.123    8   \n",
       "\n",
       "   liveness  loudness  mode  speechiness    tempo  valence  \n",
       "0    0.3460    -1.828     0       0.0525  166.969    0.814  \n",
       "1    0.1510    -5.559     1       0.0868  174.003    0.816  \n",
       "2    0.1030   -13.879     1       0.0362   99.488    0.368  \n",
       "3    0.0985   -12.178     0       0.0395  171.758    0.227  \n",
       "4    0.2020   -21.150     0       0.0456  140.576    0.390  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df2.drop(columns=['genre','artist_name','track_name','track_id','popularity','time_signature'],axis=1)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Tworzenie obiektu encodera\n",
    "encoder = LabelEncoder()\n",
    "# Konwersja kolumny z kategoriami na numeryczn\n",
    "a['key'] = encoder.fit_transform(a['key'])\n",
    "a['mode']=encoder.fit_transform(a['mode'])\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "11f72bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.68560452e-01  5.54364469e-01  2.35122339e+05  5.70957673e-01\n",
      "  1.48301234e-01  5.34446665e+00  2.15009285e-01 -9.56988540e+00\n",
      "  3.47968633e-01  1.20765015e-01  1.17666585e+02  4.54916856e-01]\n",
      "[3.54767277e-01 1.85607826e-01 1.18935654e+05 2.63454996e-01\n",
      " 3.02767714e-01 3.46163324e+00 1.98272159e-01 5.99819074e+00\n",
      " 4.76326005e-01 1.85517907e-01 3.08988402e+01 2.60064925e-01]\n"
     ]
    }
   ],
   "source": [
    "std2 = StandardScaler()\n",
    "std2.fit(a)\n",
    "print(std2.mean_)\n",
    "print(std2.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d2550e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_predict(data):\n",
    "    #Data must be 2d Array\n",
    "    #Make sure model is in same directory\n",
    "    \n",
    "    mean = np.array([ 3.68560452e-01, 5.54364469e-01, 2.35122339e+05, 5.70957673e-01,\n",
    "                      1.48301234e-01, 5.34446665e+00, 2.15009285e-01, -9.56988540e+00,\n",
    "                      3.47968633e-01, 1.20765015e-01, 1.17666585e+02, 4.54916856e-01])\n",
    "    \n",
    "    stddev =   np.array([3.54767277e-01, 1.85607826e-01, 1.18935654e+05, 2.63454996e-01,\n",
    " 3.02767714e-01, 3.46163324e+00, 1.98272159e-01, 5.99819074e+00,\n",
    " 4.76326005e-01, 1.85517907e-01, 3.08988402e+01, 2.60064925e-01])\n",
    "    \n",
    "    scalled = (data - mean)/stddev\n",
    "    predict_proba = model2.predict(scalled)[0][0]\n",
    "    predicted = predict_proba >= 0.5\n",
    "    return predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "46bda89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [116]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m case1 \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#print(\"data:\\n\",case1)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#print('\\n')\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mnew_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcase1\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n",
      "Input \u001b[1;32mIn [115]\u001b[0m, in \u001b[0;36mnew_predict\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      9\u001b[0m    stddev \u001b[38;5;241m=\u001b[39m   np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m3.54767277e-01\u001b[39m, \u001b[38;5;241m1.85607826e-01\u001b[39m, \u001b[38;5;241m1.18935654e+05\u001b[39m, \u001b[38;5;241m2.63454996e-01\u001b[39m,\n\u001b[0;32m     10\u001b[0m \u001b[38;5;241m3.02767714e-01\u001b[39m, \u001b[38;5;241m3.46163324e+00\u001b[39m, \u001b[38;5;241m1.98272159e-01\u001b[39m, \u001b[38;5;241m5.99819074e+00\u001b[39m,\n\u001b[0;32m     11\u001b[0m \u001b[38;5;241m4.76326005e-01\u001b[39m, \u001b[38;5;241m1.85517907e-01\u001b[39m, \u001b[38;5;241m3.08988402e+01\u001b[39m, \u001b[38;5;241m2.60064925e-01\u001b[39m])\n\u001b[0;32m     13\u001b[0m    scalled \u001b[38;5;241m=\u001b[39m (data \u001b[38;5;241m-\u001b[39m mean)\u001b[38;5;241m/\u001b[39mstddev\n\u001b[1;32m---> 14\u001b[0m    predict_proba \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscalled\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     15\u001b[0m    predicted \u001b[38;5;241m=\u001b[39m predict_proba \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     16\u001b[0m    \u001b[38;5;28;01mreturn\u001b[39;00m predict_proba\n",
      "File \u001b[1;32mE:\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mE:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py:2317\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2308\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m   2309\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   2310\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2311\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2314\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m   2315\u001b[0m         )\n\u001b[1;32m-> 2317\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2318\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2320\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2321\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2325\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2327\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2328\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2330\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   2331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n",
      "File \u001b[1;32mE:\\Anaconda\\lib\\site-packages\\keras\\engine\\data_adapter.py:1579\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cluster_coordinator\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 1579\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\Anaconda\\lib\\site-packages\\keras\\engine\\data_adapter.py:1259\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[0;32m   1258\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1259\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1269\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1274\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mE:\\Anaconda\\lib\\site-packages\\keras\\engine\\data_adapter.py:345\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    342\u001b[0m         flat_dataset \u001b[38;5;241m=\u001b[39m flat_dataset\u001b[38;5;241m.\u001b[39mshuffle(\u001b[38;5;241m1024\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(epochs)\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m--> 345\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mindices_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mslice_batch_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2337\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[1;34m(self, map_func, name)\u001b[0m\n\u001b[0;32m   2304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_map\u001b[39m(\u001b[38;5;28mself\u001b[39m, map_func, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2305\u001b[0m   \u001b[38;5;124;03m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001b[39;00m\n\u001b[0;32m   2306\u001b[0m \n\u001b[0;32m   2307\u001b[0m \u001b[38;5;124;03m  The type signature is:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2335\u001b[0m \u001b[38;5;124;03m    A new `Dataset` with the transformation applied as described above.\u001b[39;00m\n\u001b[0;32m   2336\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2337\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFlatMapDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5591\u001b[0m, in \u001b[0;36mFlatMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[0;32m   5589\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_structure \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39moutput_structure\u001b[38;5;241m.\u001b[39m_element_spec  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   5590\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m-> 5591\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mflat_map_dataset(\n\u001b[0;32m   5592\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   5593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   5594\u001b[0m     f\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction,\n\u001b[0;32m   5595\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n\u001b[0;32m   5596\u001b[0m \u001b[38;5;28msuper\u001b[39m(FlatMapDataset, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(input_dataset, variant_tensor)\n",
      "File \u001b[1;32mE:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:2375\u001b[0m, in \u001b[0;36mflat_map_dataset\u001b[1;34m(input_dataset, other_arguments, f, output_types, output_shapes, metadata, name)\u001b[0m\n\u001b[0;32m   2373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   2374\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2375\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2376\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFlatMapDataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_arguments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2377\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2378\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   2380\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Szukaj po wszystkich\n",
    "model2 = keras.models.load_model('model/Spotify_model')\n",
    "for i in range(len(a)):\n",
    "    case1 = a.loc[1]\n",
    "    #print(\"data:\\n\",case1)\n",
    "    #print('\\n')\n",
    "    score = new_predict([case1])\n",
    "    if score > 0.5:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9010af63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      " acousticness             0.639000\n",
      "danceability             0.690000\n",
      "duration_ms         235067.000000\n",
      "energy                   0.317000\n",
      "instrumentalness         0.000049\n",
      "key                      9.000000\n",
      "liveness                 0.110000\n",
      "loudness               -11.316000\n",
      "mode                     0.000000\n",
      "speechiness              0.032600\n",
      "tempo                  127.956000\n",
      "valence                  0.280000\n",
      "Name: 7570, dtype: float64\n",
      "\n",
      "\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "0.5411126\n"
     ]
    }
   ],
   "source": [
    "#Szukaj konkretny\n",
    "model2 = keras.models.load_model('model/Spotify_model')\n",
    "case1 = a.loc[7570]\n",
    "print(\"data:\\n\",case1)\n",
    "print('\\n')\n",
    "score = new_predict([case1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58255805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "91bb753b057673435fb8d6f6a083e6c818364728098c7ae050ca3a25357dd754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
